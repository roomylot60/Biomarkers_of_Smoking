{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body signal of smoking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Importing packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking = pd.read_csv('../data/Smoking_raw/smoking.csv')\n",
    "pd.set_option('display.max_columns',30)\n",
    "smoking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nThere are totally {} null values in the dataset\".format(smoking.isnull().sum().sum())) # for checking null counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 전처리 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_scaling):\n",
    "    # Remove columns not necessary\n",
    "    if 'ID' in df_scaling:\n",
    "        df_scaling = df_scaling.drop(\"ID\", axis = 1)\n",
    "        if len(df_scaling.columns) == 1:\n",
    "            return df_scaling\n",
    "        \n",
    "        # Oral(=구강검사 여부) 특성값은 모두 Y 값이므로 삭제.\n",
    "        df_scaling = df_scaling.drop('oral', axis = 1) \n",
    "        \n",
    "        # Categorical features label encoding\n",
    "        cate_features = df_scaling[['gender','tartar']]\n",
    "\n",
    "        lbe = LabelEncoder()\n",
    "        lbe.fit_transform(df_scaling[\"gender\"])\n",
    "        df_scaling[\"gender\"] = lbe.fit_transform(df_scaling[\"gender\"])\n",
    "\n",
    "        lbe = LabelEncoder()\n",
    "        lbe.fit_transform(df_scaling[\"tartar\"])\n",
    "        df_scaling[\"tartar\"] = lbe.fit_transform(df_scaling[\"tartar\"])\n",
    "        \n",
    "        # hearing feature converting values 1, 2 => 1, 0\n",
    "        df_scaling['hearing(left)'] = df_scaling['hearing(left)'].apply(lambda x: x-2 if x == 2.0 else x )\n",
    "        df_scaling['hearing(right)'] = df_scaling['hearing(right)'].apply(lambda x: x-2 if x == 2.0 else x )\n",
    "        \n",
    "        # BMI 지수 계산 : bmi = kg/m^2\n",
    "        df_scaling['bmi'] = df_scaling['weight(kg)']/((df_scaling['height(cm)']*0.01)**2)\n",
    "        # wwi(비만 지수) 지수 계산 : wwi = cm/sqrt(kg)\n",
    "        df_scaling['wwi'] = df_scaling['waist(cm)']/(df_scaling['weight(kg)'].apply(np.sqrt))\n",
    "\n",
    "    return df_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessing(smoking)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation value with heatmap\n",
    "df.corr().style.background_gradient(cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Competition Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competition_format\n",
    "x_train = pd.read_csv('../data/Smoking_raw/competition_format/x_train.csv')\n",
    "x_test = pd.read_csv('../data/Smoking_raw/competition_format/x_test.csv')\n",
    "y_train = pd.read_csv('../data/Smoking_raw/competition_format/y_train.csv')\n",
    "y_test = pd.read_csv('../data/Smoking_raw/competition_format/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessing(x_train)\n",
    "x_test = preprocessing(x_test)\n",
    "y_train = preprocessing(y_train) # remove 'ID', 'oral' columns\n",
    "y_test = preprocessing(y_test) # remove 'ID', 'oral' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Scaler 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(train_data, test_data, scaled_form = 'MinMaxScaler()'):\n",
    "    # 형태 별 특성 구분\n",
    "    train_data = preprocessing(train_data)\n",
    "    test_data = preprocessing(test_data)\n",
    "    tr_cate_features = train_data[['gender', 'tartar', 'hearing(right)', 'hearing(left)', 'dental caries']]\n",
    "    tr_scaled_features = train_data.drop(tr_cate_features.columns, axis=1)\n",
    "    \n",
    "    ts_cate_features = test_data[['gender', 'tartar', 'hearing(right)', 'hearing(left)', 'dental caries']]\n",
    "    ts_scaled_features = test_data.drop(ts_cate_features.columns, axis=1)\n",
    "    \n",
    "    if scaled_form == 'StandardScaler()':\n",
    "        # Standard scaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(tr_scaled_features) # 훈련 데이터에 fit() 적용\n",
    "        \n",
    "        # 훈련 데이터와 테스트 데이터에 transform()을 통해 변환\n",
    "        tr_scaled = scaler.transform(tr_scaled_features)\n",
    "        ts_scaled = scaler.transform(ts_scaled_features)\n",
    "        \n",
    "        train_std_scaled = pd.DataFrame(tr_scaled, columns=tr_scaled_features.columns)\n",
    "        train_std_scaled[tr_cate_features.columns] = tr_cate_features\n",
    "        \n",
    "        test_std_scaled = pd.DataFrame(ts_scaled, columns=ts_scaled_features.columns)\n",
    "        test_std_scaled[ts_cate_features.columns] = ts_cate_features\n",
    "        \n",
    "        return train_std_scaled, test_std_scaled\n",
    "    \n",
    "    elif scaled_form == 'RobustScaler()':\n",
    "        # Robust scaler\n",
    "        scaler = RobustScaler()\n",
    "        scaler.fit(tr_scaled_features) # 훈련 데이터에 fit() 적용\n",
    "        \n",
    "        # 훈련 데이터와 테스트 데이터에 transform()을 통해 변환\n",
    "        tr_scaled = scaler.transform(tr_scaled_features)\n",
    "        ts_scaled = scaler.transform(ts_scaled_features)\n",
    "        \n",
    "        # 데이터 프레임 형태로 변환\n",
    "        train_robust_scaled = pd.DataFrame(tr_scaled, columns=tr_scaled_features.columns)\n",
    "        train_robust_scaled[tr_cate_features.columns] = tr_cate_features\n",
    "        \n",
    "        test_robust_scaled = pd.DataFrame(ts_scaled, columns=ts_scaled_features.columns)\n",
    "        test_robust_scaled[ts_cate_features.columns] = ts_cate_features\n",
    "        \n",
    "        return train_robust_scaled, test_robust_scaled\n",
    "        \n",
    "    else:\n",
    "        # MinMax scaler\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(tr_scaled_features) # 훈련 데이터에 fit() 적용\n",
    "        \n",
    "        # 훈련 데이터와 테스트 데이터에 transform()을 통해 변환\n",
    "        tr_scaled = scaler.transform(tr_scaled_features)\n",
    "        ts_scaled = scaler.transform(ts_scaled_features)\n",
    "        \n",
    "        # 데이터 프레임 형태로 변환\n",
    "        train_mmx_scaled = pd.DataFrame(tr_scaled, columns = tr_scaled_features.columns)\n",
    "        train_mmx_scaled[tr_cate_features.columns] = tr_cate_features\n",
    "        \n",
    "        test_mmx_scaled = pd.DataFrame(ts_scaled,columns = ts_scaled_features.columns)\n",
    "        test_mmx_scaled[ts_cate_features.columns] = ts_cate_features\n",
    "\n",
    "        return train_mmx_scaled, test_mmx_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = scaling(x_train, x_test, 'StandardScaler()')\n",
    "# x_train, x_test = scaling(x_train, x_test, 'RobustScaler()')\n",
    "# x_train, x_test = scaling(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train 시각화\n",
    "x_train.hist(figsize = (20, 20), bins = 12, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test 시각화\n",
    "x_test.hist(figsize = (20, 20), bins = 12, legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    data = df, x = \"age\", hue = \"smoking\",\n",
    "    kind = \"hist\", height = 5, aspect = 1.5,\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.50\").set(title =  \"density relationship between 'age' and 'smoking' variables\");\n",
    "\n",
    "\n",
    "sns.displot(\n",
    "    data = df, x = \"systolic\", hue = \"smoking\",\n",
    "    kind = \"kde\", height = 5, aspect = 1.5,\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.50\").set(title = \"density relationship between 'systolic' and 'smoking' variables\");\n",
    "\n",
    "\n",
    "sns.displot(\n",
    "    data = df, x = \"waist(cm)\", hue = \"smoking\",\n",
    "    kind = \"kde\", height = 5, aspect = 1.5,\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.50\").set(title = \"density relationship between 'waist(cm)' and 'smoking' variables\");\n",
    "\n",
    "sns.displot(\n",
    "    data = df, x = \"bmi\", hue = \"smoking\",\n",
    "    kind = \"kde\", height = 5, aspect = 1.5,\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.50\").set(title = \"density relationship between 'bmi' and 'smoking' variables\");\n",
    "\n",
    "sns.displot(\n",
    "    data = df, x = \"wwi\", hue = \"smoking\",\n",
    "    kind = \"kde\", height = 5, aspect = 1.5,\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.50\").set(title = \"density relationship between 'wwi' and 'smoking' variables\");\n",
    "\n",
    "sns.displot(\n",
    "    data = df, x = \"triglyceride\", hue = \"smoking\",\n",
    "    kind = \"kde\", height = 5, aspect = 1.5,\n",
    "    palette=\"ch:rot=-.25,hue=1,light=.50\").set(title = \"density relationship between 'wwi' and 'smoking' variables\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline : Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # for modeling\n",
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "\n",
    "# 랜덤포레스트 객체 생성\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_estimators=2000)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_pred_probs = rf_clf.predict_proba(x_test)[:, 1]\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(rf_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test,pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, rf_pred, rf_pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General parameter\n",
    "- booster\n",
    "    - gbtree(tree based model) 또는 gblinear(linear model) 중 선택\n",
    "    - Default = 'gbtree'\n",
    "- silent\n",
    "    - 출력 메시지 설정 관련 인수(나타내고 싶지 않을 경우 1로 설정)\n",
    "    - Default = 1\n",
    "- nthread\n",
    "    - CPU 실행 스레드 개수 조정\n",
    "    - Default는 전체 다 사용하는 것\n",
    "    - 멀티코어/스레드 CPU 시스템에서 일부CPU만 사용할 때 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boost Parameter\n",
    "- eta: Learning rate (일반적으로 0.01 - 0.2)\n",
    "    - 범위는 0 ~ 1로 클 수록 모형의 업데이트 속도는 빨라지지만, 과적합의 이슈 발생 가능성이 높음\n",
    "- min_child_weight: min_child_weight를 기준으로 추가 분기 결정 (크면 Underfitting)\n",
    "    - Default : 1\n",
    "    - leaf node에 포함되는 최소 관측치의 수를 의미\n",
    "    - 작은 값을 가질수록 과적합 발생 가능성이 높음 (과적합 조절 용도로 사용됨)\n",
    "    - 범위: 0 ~ ∞\n",
    "- max_depth: Tree 깊이 수\n",
    "    - Default : 6\n",
    "    - 트리의 최대 깊이를 설정\n",
    "    - 0 을 지정하면 깊이의 제한이 없음\n",
    "    - 과적합에 가장 민감하게 작용하는 파라미터 중 하나임 (과적합 조절 용도로 사용됨)\n",
    "    - 범위: 0 ~ ∞\n",
    "- max_leaf_node: 하나의 트리에서 node 개수\n",
    "- gamma: split 하기 위한 최소의 loss 감소 정의\n",
    "    - Default : 0\n",
    "    - leaf node의 추가 분할을 결정할 최소손실 감소값\n",
    "    - 해당 값보다 손실이 크게 감소할 때 분리\n",
    "    - 값이 클수록 과적합 감소효과\n",
    "    - 범위: 0 ~ ∞\n",
    "- subsample\n",
    "    - Default : 1\n",
    "    - 학습 시 데이터 샘플링 비율을 지정(과적합 제어)\n",
    "    - 일반적으로 0.5 ~ 1 사이의 값을 사용\n",
    "    - 범위: 0 ~ 1\n",
    "- colsample_bytree\n",
    "    - Default : 1\n",
    "    - 트리 생성에 필요한 feature의 샘플링에 사용\n",
    "    - feature가 많을 때 과적합 조절에 사용\n",
    "    - 범위: 0 ~ 1\n",
    "- colsample_bylevel: 각 level마다 샘플링 비율\n",
    "- lambda\n",
    "    - Default : 1\n",
    "    - L2 Regularization 적용 값\n",
    "    - feature 개수가 많을 때 적용 검토\n",
    "    - 클수록 과적합 감소 효과\n",
    "- alpha: L1 norm\n",
    "    - Default : 0\n",
    "    - L1 Regularization 적용 값\n",
    "    - feature 개수가 많을 때 적용 검토\n",
    "    - 클수록 과적합 감소 효과\n",
    "\n",
    "- scale_pos_weight: positive, negative weight 지정\n",
    "    - Default : 1\n",
    "    - 불균형 데이터셋의 균형을 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train parameter\n",
    "- objective\t\n",
    "    - reg:linear : 회귀\n",
    "    - binary:logistic : 이진분류\n",
    "    - multi:softmax : 다중분류, 클래스 반환\n",
    "    - multi:softprob : 다중분류, 확률반환\n",
    "- eval_metric : 검증에 사용되는 함수정의, 회귀 분석인 경우 'rmse'를, 클래스 분류 문제인 경우 'error'\n",
    "    - rmse : Root Mean Squared Error\n",
    "    - mae : mean absolute error\n",
    "    - logloss : Negative log-likelihood\n",
    "    - error : binary classification error rate\n",
    "    - merror : multiclass classification error rate\n",
    "    - mlogloss: Multiclass logloss\n",
    "    - auc: Area Under Curve\n",
    "- seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Python wrapper를 사용한 XGB 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 DMarix 형태로 변환 후 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "# adjusting data into DMatirx type\n",
    "dtrain = xgb.DMatrix(data=x_train,label=y_train,feature_names=x_train.columns)\n",
    "dtest = xgb.DMatrix(data=x_test,label=y_test,feature_names=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'eta':0.1, # XGBClassifier일 경우 learning_rate 로 쓴다\n",
    "          'objective':'binary:logistic', # 목적함수 : target 데이터가 0 or 1 이므로 이진 로지스틱 사용\n",
    "          'eval_metric':'logloss', # 오류 함수의 평가 성능 지표 : logloss\n",
    "          'early_stoppings':100, # 100회이상 시행시에도 오류가 내려가지않으면 중단\n",
    "          'silent' : 0, # 출력 메시지 설정 관련 인수(나타내고 싶지 않을 경우 1로 설정)\n",
    "          'verbosity':0}\n",
    "          \n",
    "num_rounds = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "start = time.time()\n",
    "xgb_model = xgb.train(params = params, dtrain=dtrain,num_boost_round= num_rounds,\n",
    "                      early_stopping_rounds=100,evals = wlist)\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start)) # 29.5 sec\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "preds = [1 if x > 0.5 else 0 for x in pred_probs]\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 평가지표 시각화(오차행렬, ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test,pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test.values, pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,12)) # 축 반환\n",
    "plot_importance(xgb_model,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_trees : 그림을 여러개 그릴시 그림 번호\n",
    "# rankdir : 트리의 방향, 디폴트는 위아래 방향\n",
    "# rankdir=\"LR\" : 왼쪽에서 오른쪽 방향으로 트리를 보여준다.\n",
    "xgb.plot_tree(xgb_model, num_trees=0, rankdir='LR')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "\n",
    "# 이미지 저장하고 싶다면\n",
    "# fig.savefig('xgb_tree_py_wp.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scikit-leran wrapper를 사용한 XGB 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Initiate XGBoost Classifier\n",
    "# xgb_clf = XGBClassifier(learning_rate=0.1,n_estimators=2000,max_depth=3,\n",
    "#                         silent=True,\n",
    "#                         objective='binary:logistic',\n",
    "#                         booster='gbtree',\n",
    "#                         n_jobs=1,\n",
    "#                         nthread=None,\n",
    "#                         gamma=0,\n",
    "#                         min_child_weight=1,\n",
    "#                         max_delta_step=0,\n",
    "#                         subsample=1,\n",
    "#                         colsample_bytree=1,\n",
    "#                         colsample_bylevel=1,\n",
    "#                         reg_alpha=0,\n",
    "#                         reg_lambda=1,\n",
    "#                         scale_pos_weight=1,\n",
    "#                         base_score=0.5,\n",
    "#                         random_state=0,\n",
    "#                         seed=None,\n",
    "#                         missing=None)\n",
    "# # Print default setting\n",
    "# xgb_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1,n_estimators=2000,max_depth=3,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        booster='gbtree',\n",
    "                        n_jobs=1,\n",
    "                        nthread=None,\n",
    "                        gamma=0).fit(x_train,y_train)\n",
    "# Make prediction\n",
    "xgb_pred = xgb_clf.predict(x_test)\n",
    "# Get predicted probability\n",
    "xgb_pred_probs = xgb_clf.predict_proba(x_test)[:,1]\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start)) # \n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,xgb_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 평가지표 시각화(오차행렬, ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, xgb_pred, xgb_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(xgb_clf, x_test, y_test, cmap = plt.cm.Blues, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test.values, xgb_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,12)) # 축 반환\n",
    "plot_importance(xgb_clf,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_trees : 그림을 여러개 그릴시 그림 번호\n",
    "# rankdir : 트리의 방향, 디폴트는 위아래 방향\n",
    "# rankdir=\"LR\" : 왼쪽에서 오른쪽 방향으로 트리를 보여준다.\n",
    "xgb.plot_tree(xgb_clf, num_trees=0, rankdir='LR')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "\n",
    "# 이미지 저장하고 싶다면\n",
    "# fig.savefig('xgb_tree_skl_wp.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Grid Search를 이용하여 최적 하이퍼 파라미터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# xgb 모델 생성\n",
    "xgb = XGBClassifier(learning_rate=0.1,n_estimators=2000,\n",
    "                    gamma=0, \n",
    "                    subsample=0.8, # 각 트리마다의 관측 데이터 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                    colsample_bytree=0.8, # 각 트리마다의 feature 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                    objective= 'binary:logistic', \n",
    "                    verbose=10)\n",
    "\n",
    "# parameter 들을 dictionary 형태로 설정\n",
    "xgb_params = { \n",
    "              'max_depth':range(3,13,3), \n",
    "              'min_child_weight':range(1,6,2)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# GridSearch를 통해 최적 hyperparameter를 검색\n",
    "clf = GridSearchCV(xgb,xgb_params,scoring='accuracy',cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.best_params_)\n",
    "pred = clf.predict(x_test)\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,pred)))\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb 모델 생성\n",
    "xgb = XGBClassifier(learning_rate=0.1, \n",
    "                    n_estimators=2000,\n",
    "                    max_depth=3,\n",
    "                    min_child_weight=3,\n",
    "                    gamma=0, \n",
    "                    subsample=0.8, # 각 트리마다의 관측 데이터 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                    colsample_bytree=0.8, # 각 트리마다의 feature 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                    objective= 'binary:logistic', \n",
    "                    verbose=10)\n",
    "\n",
    "# parameter 들을 dictionary 형태로 설정\n",
    "xgb_params = { \n",
    "              'gamma':[i/10.0 for i in range(0,5)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# GridSearch를 통해 최적 hyperparameter를 검색\n",
    "clf = GridSearchCV(xgb,xgb_params,scoring='accuracy',cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.best_params_)\n",
    "pred = clf.predict(x_test)\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,pred)))\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb 모델 생성\n",
    "xgb = XGBClassifier(learning_rate=0.1, \n",
    "                    n_estimators=2000,\n",
    "                    max_depth=3,\n",
    "                    min_child_weight=3,\n",
    "                    gamma=0, \n",
    "                    subsample=0.8, # 각 트리마다의 관측 데이터 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                    colsample_bytree=0.8, # 각 트리마다의 feature 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                    objective= 'binary:logistic', \n",
    "                    verbose=10)\n",
    "\n",
    "# parameter 들을 dictionary 형태로 설정\n",
    "xgb_params = { \n",
    "              'subsample':[i/10.0 for i in range(6,10)],\n",
    "              'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# GridSearch를 통해 최적 hyperparameter를 검색\n",
    "clf = GridSearchCV(xgb,xgb_params,scoring='accuracy',cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.best_params_)\n",
    "pred = clf.predict(x_test)\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,pred)))\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1, \n",
    "                        n_estimators=2000,\n",
    "                        max_depth=6,\n",
    "                        min_child_weight=3,\n",
    "                        gamma=0, \n",
    "                        subsample=0.9, # 각 트리마다의 관측 데이터 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                        colsample_bytree=0.8, # 각 트리마다의 feature 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                        objective= 'binary:logistic', \n",
    "                        verbose=10).fit(x_train,y_train)\n",
    "# Make prediction\n",
    "xgb_pred = xgb_clf.predict(x_test)\n",
    "# Get predicted probability\n",
    "xgb_pred_probs = xgb_clf.predict_proba(x_test)[:,1]\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start)) # \n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,xgb_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 하이퍼파라미터 수정 후, 평가지표 시각화(오차행렬, ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, xgb_pred, xgb_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(xgb_clf, x_test, y_test, cmap = 'summer', normalize = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# num_trees : 그림을 여러개 그릴시 그림 번호\n",
    "# rankdir : 트리의 방향, 디폴트는 위아래 방향\n",
    "# rankdir=\"LR\" : 왼쪽에서 오른쪽 방향으로 트리를 보여준다.\n",
    "xgb.plot_tree(xgb_clf, num_trees=0, rankdir='LR')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "\n",
    "# 이미지 저장하고 싶다면\n",
    "# fig.savefig('xgb_clf_tree.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test.values, xgb_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "- num_iterations : 수행 반복 횟수\n",
    "    - Default : 100)\n",
    "    - 학습에 활용될 weak learner의 반복 수\n",
    "- learning_rate : 학습률\n",
    "    - Default : 0.1\n",
    "    - 일반적으로 확습률(learning rate)로 불리우는 파라미터\n",
    "    - weak learner의 반영 수준을 나타냄\n",
    "    - 범위는 0 ~ 1로 클 수록 모형의 업데이트 속도는 빨라짐. 클 수록 과적합의 이슈 발생 가능성이 높음\n",
    "- max_depth : 최대 깊이\n",
    "    - Default : -1\n",
    "    - 트리의 최대 깊이를 설정\n",
    "    - 0을 지정하면 깊이의 제한이 없음\n",
    "    - 과적합에 가장 민감하게 작용하는 파라미터 중 하나임 (과적합 조절 용도로 사용됨)\n",
    "    - 범위: 0 ~ ∞\n",
    "- min_data_in_leaf : 노드 별 leaf 최소 개수\n",
    "    - Default : 20\n",
    "    - 최종 leaf node가 되기 위한 최소 레코드 수\n",
    "    - 과적합 제어용으로 활용\n",
    "- num_leaves\n",
    "    - Default : 31\n",
    "    - 하나의 트리가 가지는 최대 leaf 수\n",
    "- boosting\n",
    "    - Default : 'gbdt'\n",
    "    - 실행하고자 하는 알고리즘 타입 정의\n",
    "        - gdbt : Gradient Boosting Decision Tree\n",
    "        - rf : Random Forest\n",
    "        - dart : Dropouts meet Multiple Additive Regression Trees\n",
    "        - goss : Gradient-based One-Side Sampling\n",
    "- bagging_fraction\n",
    "    - Default : 1.0)\n",
    "    - 데이터 샘플링 비율\n",
    "    - 과적합 제어용\n",
    "- feature_fraction\n",
    "    - Default 1.0)\n",
    "    - 개별 트리 학습 시 선택하는 feature 비율\n",
    "    - 과적합 제어용\n",
    "- lamda_l2\n",
    "    - Default : 0\n",
    "    - L2 Regularization 적용 값\n",
    "    - feature 개수가 많을 때 적용 검토\n",
    "    - 클수록 과적합 감소 효과\n",
    "- lamda_l1\n",
    "    - Default : 0\n",
    "    - L1 Regularization 적용 값\n",
    "    - feature 개수가 많을 때 적용 검토\n",
    "    - 클수록 과적합 감소 효과\n",
    "- objective\n",
    "    - Default : regression\n",
    "        - regression : 회귀\n",
    "        - binary : 이진분류\n",
    "        - multiclass : 다중분류\n",
    "- early_stopping_round\n",
    "    - Default : 0\n",
    "    - 이전 학습 대비 일정 수준 이상의 성능 효과가 없을 시 학습을 중단함\n",
    "    - 지나친 iteration을 줄이는데 도움이 되기 때문에, 학습 속도를 높일 수 있음\n",
    "- min_gain_to_split\n",
    "    - Default : 0\n",
    "    - 트리를 분기하기 위해 필요한 최소한의 gain\n",
    "- max_cat_threshold\n",
    "    - Default : 32\n",
    "    - 카테고리 그룹을 정의된 수로 합치고 그룹 경계선에서 분기 포인트 searching\n",
    "    - 카테고리 수가 클 때, 과적합을 방지하는 분기 포인트 searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance # for visualization about features' importance by using plot_importance()\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=2000)\n",
    "evals = [(x_test,y_test)]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 학습 : 조기중단 수행(100)\n",
    "lgbm_clf.fit(x_train,y_train, \n",
    "             early_stopping_rounds=100, \n",
    "             eval_metric='logloss', \n",
    "             eval_set=evals, \n",
    "             verbose=True)\n",
    "                \n",
    "\n",
    "# 예측\n",
    "preds = lgbm_clf.predict(x_test)\n",
    "pred_probs = lgbm_clf.predict_proba(x_test)[:, 1]\n",
    "end = time.time()\n",
    "print(\"LGBM 수행 시간: {0:.1f} 초 \".format(end - start)) # 10.1 sec\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgbm_clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 평가지표 시각화(오차행렬, ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lgbm_clf, x_test, y_test, cmap = plt.cm.Greens, normalize = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test.values, pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='red',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(lgbm_clf, ax=ax,importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb.plot_tree(lgbm_clf)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "\n",
    "# 이미지 저장하고 싶다면\n",
    "# fig.savefig('lgbm_tree.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Grid Search를 이용하여 최적 하이퍼파라미터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Generate the Light GBM model\n",
    "lgbm_clf = LGBMClassifier(learning_rate=0.1,n_estimators=2000,\n",
    "                           subsample=0.8, # 각 트리마다의 관측 데이터 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                           colsample_bytree=0.8, # 각 트리마다의 feature 샘플링 비율, default = 1, 일반적으로 0.5 ~ 1\n",
    "                           verbose=10)\n",
    "\n",
    "# parameter 들을 dictionary 형태로 설정\n",
    "lgbm_params = {'num_leaves':[33,65,97,129], #  num_leaves = 2^(max_depth)는 depth-wise tree와 같은 수의 leaves를 가지게 하여, 이보다 작게 설정해야 오버피팅을 줄일 수 있다.\n",
    "               'max_depth':[-1,3,6,9,12], \n",
    "               'min_child_samples':[5,10,15],\n",
    "               'min_child_weight':[1,3,5,7],\n",
    "               'reg_alpha':[0,0.01,0.03]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# GridSearch를 통해 최적 hyperparameter를 검색\n",
    "grid_lgbm_clf = GridSearchCV(lgbm_clf,lgbm_params,scoring='accuracy',cv=5)\n",
    "grid_lgbm_clf.fit(x_train, y_train)\n",
    "print(grid_lgbm_clf.best_params_)\n",
    "pred = grid_lgbm_clf.predict(x_test)\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,pred)))\n",
    "end = time.time()\n",
    "print(\"LGBM 수행 시간: {0:.1f} 초 \".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_1 = LGBMClassifier(n_estimators=2000,max_depth=3,min_child_smaples=1,min_child_weight=5,num_leaves=20,reg_alpha=0)\n",
    "evals = [(x_test,y_test)]\n",
    "\n",
    "start = time.time()\n",
    "# 학습 : 조기중단 수행(100)\n",
    "lgbm_clf_1.fit(x_train,y_train,early_stopping_rounds=100,\n",
    "                eval_metric='logloss',eval_set=evals, verbose=True)\n",
    "\n",
    "# 예측\n",
    "preds = lgbm_clf_1.predict(x_test)\n",
    "pred_proba = lgbm_clf_1.predict_proba(x_test)[:, 1]\n",
    "end = time.time()\n",
    "print(\"LGBM 수행 시간: {0:.1f} 초 \".format(end - start))\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaler 별 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 이상치 탐색(with IQR) 및 제거 후 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier detection with IQR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def outlier_detection(df, n, columns):\n",
    "    rows = []\n",
    "    will_drop_train = []\n",
    "    for col in columns:\n",
    "        Q1 = np.nanpercentile(df[col], 25)\n",
    "        Q3 = np.nanpercentile(df[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_point = 1.5 * IQR\n",
    "        rows.extend(df[(df[col] < Q1 - outlier_point)|(df[col] > Q3 + outlier_point)].index)\n",
    "    for r, c in Counter(rows).items():\n",
    "        if c >= n: will_drop_train.append(r)\n",
    "    return will_drop_train\n",
    "\n",
    "will_drop_train = outlier_detection(df, 5, df.select_dtypes([\"float\", \"int\"]).columns)\n",
    "will_drop_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "will_drop_train = outlier_detection(x_train, 5, x_train.select_dtypes([\"float\", \"int\"]).columns)\n",
    "will_drop_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(will_drop_train, inplace = True, axis = 0)\n",
    "y_train.drop(will_drop_train, inplace = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(will_drop_train, inplace = True, axis = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 XGB : Python wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after deleting outlier data\n",
    "\n",
    "wlist = [(dtrain,'train'),(dtest,'eval')]\n",
    "start = time.time()\n",
    "xgb_model = xgb.train(params = params, dtrain=dtrain,num_boost_round= num_rounds,\n",
    "                      early_stopping_rounds=100,evals = wlist)\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start)) # 29.1 sec\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "preds = [1 if x > 0.5 else 0 for x in pred_probs]\n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test,pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_trees : 그림을 여러개 그릴시 그림 번호\n",
    "# rankdir : 트리의 방향, 디폴트는 위아래 방향\n",
    "# rankdir=\"LR\" : 왼쪽에서 오른쪽 방향으로 트리를 보여준다.\n",
    "xgb.plot_tree(xgb_model, num_trees=0, rankdir='LR')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(150, 100)\n",
    "\n",
    "# 이미지 저장하고 싶다면\n",
    "# fig.savefig('xgb_tree_py_wp.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 XGB : Scikit-learn wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after deleting the outlier data\n",
    "# Train the model\n",
    "start = time.time()\n",
    "xgb_clf = XGBClassifier(learning_rate=0.1,n_estimators=2000,max_depth=3,\n",
    "                        silent=True,\n",
    "                        objective='binary:logistic',\n",
    "                        booster='gbtree',\n",
    "                        n_jobs=1,\n",
    "                        nthread=None,\n",
    "                        gamma=0).fit(x_train,y_train)\n",
    "# Make prediction\n",
    "xgb_pred = xgb_clf.predict(x_test)\n",
    "# Get predicted probability\n",
    "xgb_pred_probs = xgb_clf.predict_proba(x_test)[:,1]\n",
    "end = time.time()\n",
    "print(\"XGB 수행 시간: {0:.1f} 초 \".format(end - start)) # \n",
    "print('분류 결과 : {0:.1f} '.format(accuracy_score(y_test,xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test, xgb_pred, xgb_pred_probs)\n",
    "# 평가 지표의 수치가 하락함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9271e414be5e055cabef0148537efe95905a2cbc3a51060d18455594802bc000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
